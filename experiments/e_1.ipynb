{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "# Core LangGraph imports\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# OpenAI and other LLM imports\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Research and crawling tools\n",
    "import tavily\n",
    "from tavily import TavilyClient\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from crawl4ai import AsyncWebCrawler\n",
    "from crawl4ai.async_configs import BrowserConfig, CrawlerRunConfig\n",
    "\n",
    "# For image processing and markdown\n",
    "import re\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# load env\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "tavily_client = TavilyClient(api_key=tavily_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state structure\n",
    "class BlogWritingState(BaseModel):\n",
    "    topic: str = Field(description=\"The blog topic to write about\")\n",
    "    search_results: List[Dict[str, Any]] = Field(default_factory=list, description=\"Results from Tavily search\")\n",
    "    scraped_content: Dict[str, Dict[str, Any]] = Field(default_factory=dict, description=\"Content scraped from URLs\")  # Changed type here\n",
    "    research_summary: str = Field(default=\"\", description=\"Summary of research findings\")\n",
    "    outline: List[Dict[str, Any]] = Field(default_factory=list, description=\"Outline of the blog post\")\n",
    "    draft: str = Field(default=\"\", description=\"Draft of the blog post in markdown\")\n",
    "    critique: str = Field(default=\"\", description=\"Critique of the blog post\")\n",
    "    final_draft: str = Field(default=\"\", description=\"Final version of the blog post\")\n",
    "    evaluation: Dict[str, Any] = Field(default_factory=dict, description=\"Evaluation metrics and feedback\")\n",
    "    images: List[Dict[str, Any]] = Field(default_factory=list, description=\"Images to include in the blog\")\n",
    "    output_dir: str = Field(default=\"\", description=\"Directory to save the blog post and assets\")\n",
    "    error: Optional[str] = Field(default=None, description=\"Error message if any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchTool:\n",
    "    \"\"\"Tool for researching a topic using Tavily.\"\"\"\n",
    "    \n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "    \n",
    "    def search(self, topic: str, max_results: int = 5) -> List[Dict]:\n",
    "        \"\"\"Search for relevant articles on the topic.\"\"\"\n",
    "        print(f\"Searching for articles on: {topic}\")\n",
    "        try:\n",
    "            search_result = self.client.search(query=f\"latest articles and research on {topic}\", \n",
    "                                              search_depth=\"advanced\",\n",
    "                                              max_results=max_results)\n",
    "            return search_result.get(\"results\", [])\n",
    "        except Exception as e:\n",
    "            return [{\"error\": f\"Search failed: {str(e)}\"}]\n",
    "\n",
    "research_tool = ResearchTool(tavily_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebCrawlerTool:\n",
    "    \"\"\"Tool for crawling and extracting content from websites.\"\"\"\n",
    "    \n",
    "    async def crawl_url(self, url: str) -> Dict:\n",
    "        \"\"\"Crawl a URL and extract its content.\"\"\"\n",
    "        print(f\"Crawling URL: {url}\")\n",
    "        try:\n",
    "            browser_config = BrowserConfig()\n",
    "            run_config = CrawlerRunConfig()\n",
    "            \n",
    "            async with AsyncWebCrawler(config=browser_config) as crawler:\n",
    "                result = await crawler.arun(url=url, config=run_config)\n",
    "                \n",
    "                # Extract images if available\n",
    "                images = []\n",
    "                soup = BeautifulSoup(markdown.markdown(result.markdown), 'html.parser')\n",
    "                for img in soup.find_all('img'):\n",
    "                    if img.get('src'):\n",
    "                        images.append({\n",
    "                            \"url\": img.get('src'),\n",
    "                            \"alt\": img.get('alt', ''),\n",
    "                            \"source_url\": url\n",
    "                        })\n",
    "                \n",
    "                return {\n",
    "                    \"content\": result.markdown,\n",
    "                    \"images\": images,\n",
    "                    \"url\": url,\n",
    "                    \"title\": result.metadata.get(\"title\", \"\")\n",
    "                }\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Failed to crawl {url}: {str(e)}\", \"url\": url}\n",
    "\n",
    "    def crawl_urls(self, urls: List[str]) -> Dict[str, Any]:\n",
    "        \"\"\"Crawl multiple URLs and aggregate their content.\"\"\"\n",
    "        print(f\"Crawling {len(urls)} URLs\")\n",
    "        results = {}\n",
    "        \n",
    "        async def process_urls():\n",
    "            tasks = [self.crawl_url(url) for url in urls]\n",
    "            return await asyncio.gather(*tasks)\n",
    "        \n",
    "        crawl_results = asyncio.run(process_urls())\n",
    "        \n",
    "        for result in crawl_results:\n",
    "            url = result.get(\"url\")\n",
    "            if url:\n",
    "                results[url] = result\n",
    "        \n",
    "        return results\n",
    "\n",
    "web_crawler_tool = WebCrawlerTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDownloader:\n",
    "    \"\"\"Tool for downloading and saving images.\"\"\"\n",
    "    \n",
    "    \n",
    "    def download_image(self, image_url: str, output_path: str) -> str:\n",
    "        \"\"\"Download an image and save it to the specified path.\"\"\"\n",
    "        print(f\"Downloading image from: {image_url}\")\n",
    "        try:\n",
    "            response = requests.get(image_url, stream=True)\n",
    "            if response.status_code == 200:\n",
    "                with open(output_path, 'wb') as f:\n",
    "                    shutil.copyfileobj(response.raw, f)\n",
    "                return output_path\n",
    "            else:\n",
    "                return \"\"\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "\n",
    "image_downloader = ImageDownloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent definitions\n",
    "class ResearchAgent:\n",
    "    \"\"\"Agent responsible for collecting research on a topic.\"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "        self.research_tool = research_tool\n",
    "        self.web_crawler_tool = web_crawler_tool\n",
    "    \n",
    "    def research_prompt(self):\n",
    "        return ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are a professional research agent. Your task is to gather relevant information on a given topic \n",
    "            for writing a high-quality blog post. Search for the most relevant and up-to-date information. \n",
    "            Focus on finding authoritative sources, recent developments, key concepts, and insightful perspectives.\"\"\"),\n",
    "            (\"human\", \"Research the topic: {topic}\"),\n",
    "            MessagesPlaceholder(variable_name=\"history\")\n",
    "        ])\n",
    "    \n",
    "    def summarize_prompt(self):\n",
    "        return ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are a research summarizer. Given content collected from multiple sources, create a comprehensive\n",
    "            and well-organized summary that captures the key information, trends, varied perspectives, and important details\n",
    "            on the topic. Format your summary in clear sections with markdown. Include specific facts, statistics, and quotes\n",
    "            that would be valuable for writing an authoritative blog post.\"\"\"),\n",
    "            (\"human\", \"Summarize the following research on {topic}:\\n\\n{research_content}\"),\n",
    "        ])\n",
    "    \n",
    "    def run(self, state: BlogWritingState) -> Dict:\n",
    "        \"\"\"Run the research process and update the state.\"\"\"\n",
    "        print(\"Running Research Agent\")\n",
    "        try:\n",
    "            topic = state.topic  # Use dot notation instead of dict access\n",
    "            \n",
    "            # Search for relevant articles\n",
    "            search_results = self.research_tool.search(topic)\n",
    "            \n",
    "            # Extract URLs from search results\n",
    "            urls = [result.get(\"url\") for result in search_results if result.get(\"url\")]\n",
    "            \n",
    "            # Crawl the URLs to get content\n",
    "            scraped_content = self.web_crawler_tool.crawl_urls(urls)\n",
    "            \n",
    "            # Extract all images from scraped content\n",
    "            all_images = []\n",
    "            for url, data in scraped_content.items():\n",
    "                if \"images\" in data and isinstance(data[\"images\"], list):\n",
    "                    for img in data[\"images\"]:\n",
    "                        img[\"source_url\"] = url\n",
    "                        all_images.append(img)\n",
    "            \n",
    "            # Create a research content string from scraped content\n",
    "            research_content = \"\\n\\n===SOURCE===\\n\\n\".join([\n",
    "                f\"URL: {url}\\nTITLE: {data.get('title', 'No Title')}\\n\\n{data.get('content', 'No content')}\"\n",
    "                for url, data in scraped_content.items() if \"error\" not in data\n",
    "            ])\n",
    "            \n",
    "            # Summarize the research\n",
    "            summary_chain = self.summarize_prompt() | self.llm | StrOutputParser()\n",
    "            research_summary = summary_chain.invoke({\"topic\": topic, \"research_content\": research_content})\n",
    "            \n",
    "            # Return updated state (as a dict that will be converted to new state)\n",
    "            return {\n",
    "                \"topic\": topic,\n",
    "                \"search_results\": search_results,\n",
    "                \"scraped_content\": scraped_content,\n",
    "                \"research_summary\": research_summary,\n",
    "                \"images\": all_images\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Research agent error: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlineAgent:\n",
    "    \"\"\"Agent responsible for creating a blog post outline.\"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "    \n",
    "    def outline_prompt(self):\n",
    "        return ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are an expert blog outline creator. Given a topic and research summary, create a comprehensive\n",
    "            outline for a professional blog post. The outline should include:\n",
    "            1. An engaging title\n",
    "            2. A compelling introduction section\n",
    "            3. Main sections with clear headings\n",
    "            4. Subsections where appropriate\n",
    "            5. A conclusion section\n",
    "            6. Call-to-action or next steps\n",
    "            \n",
    "            Format your outline as JSON with the following structure:\n",
    "            {\n",
    "                \"title\": \"Main Blog Title\",\n",
    "                \"sections\": [\n",
    "                    {\n",
    "                        \"heading\": \"Section Heading\",\n",
    "                        \"subheadings\": [\"Subheading 1\", \"Subheading 2\"],\n",
    "                        \"key_points\": [\"Point 1\", \"Point 2\"]\n",
    "                    }\n",
    "                ]\n",
    "            }\"\"\"),\n",
    "            (\"human\", \"\"\"Create an outline for a professional blog post on the topic: {topic}\n",
    "            \n",
    "            Here is the research summary to work with:\n",
    "            \n",
    "            {research_summary}\"\"\"),\n",
    "        ])\n",
    "    \n",
    "    def run(self, state: Dict) -> Dict:\n",
    "        \"\"\"Create an outline based on the research and update the state.\"\"\"\n",
    "        print(\"Running Outline Agent\")\n",
    "        try:\n",
    "            outline_chain = self.outline_prompt() | self.llm | JsonOutputParser()\n",
    "            outline = outline_chain.invoke({\n",
    "                \"topic\": state.topic,\n",
    "                \"research_summary\": state.research_summary\n",
    "            })\n",
    "            \n",
    "            return {**state, \"outline\": outline}\n",
    "        except Exception as e:\n",
    "            return {**state, \"error\": f\"Outline agent error: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WriterAgent:\n",
    "    \"\"\"Agent responsible for writing the blog post.\"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "    \n",
    "    def writing_prompt(self):\n",
    "        return ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are a professional blog writer with expertise in creating engaging, informative, and well-structured\n",
    "            content. Write a comprehensive blog post following the provided outline and incorporating the research summary.\n",
    "            \n",
    "            Guidelines:\n",
    "            - Write in a clear, engaging, and authoritative tone\n",
    "            - Use markdown formatting for headings, emphasis, lists, etc.\n",
    "            - Include code snippets where relevant (with proper markdown formatting)\n",
    "            - Suggest places to insert images with image descriptions in this format: ![Description](image_placeholder)\n",
    "            - Back claims with data from the research\n",
    "            - Make the introduction compelling to hook readers\n",
    "            - End with a strong conclusion and call-to-action\n",
    "            - Target a professional audience with technical accuracy but accessible explanation\n",
    "            - Aim for ~1500-2000 words of comprehensive coverage\"\"\"),\n",
    "            (\"human\", \"\"\"Write a professional blog post on the topic: {topic}\n",
    "            \n",
    "            Outline:\n",
    "            {outline}\n",
    "            \n",
    "            Research Summary:\n",
    "            {research_summary}\n",
    "            \n",
    "            Available images (suggest where to use these in your blog post):\n",
    "            {images_text}\"\"\"),\n",
    "        ])\n",
    "    \n",
    "    def run(self, state: Dict) -> Dict:\n",
    "        \"\"\"Write the blog post draft and update the state.\"\"\"\n",
    "        print(\"Running Writer Agent\")\n",
    "        try:\n",
    "            # Format images info for the prompt\n",
    "            images_text = \"\\n\".join([\n",
    "                f\"- Image {i+1}: {img.get('alt', 'No description')} (from {img.get('source_url', 'unknown')})\"\n",
    "                for i, img in enumerate(state[\"images\"][:5])  # Limit to 5 images to avoid token limits\n",
    "            ])\n",
    "            \n",
    "            outline_str = json.dumps(state.outline, indent=2) if isinstance(state.outline, dict) else str(state.outline)\n",
    "            \n",
    "            writing_chain = self.writing_prompt() | self.llm | StrOutputParser()\n",
    "            draft = writing_chain.invoke({\n",
    "                \"topic\": state.topic,\n",
    "                \"outline\": outline_str,\n",
    "                \"research_summary\": state.research_summary,\n",
    "                \"images_text\": images_text or \"No images available.\"\n",
    "            })\n",
    "            \n",
    "            return {**state, \"draft\": draft}\n",
    "        except Exception as e:\n",
    "            return {**state, \"error\": f\"Writer agent error: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CritiqueAgent:\n",
    "    \"\"\"Agent responsible for critiquing the blog post.\"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "    \n",
    "    def critique_prompt(self):\n",
    "        return ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are an expert content editor and critic. Your job is to provide constructive criticism and \n",
    "            improvement suggestions for blog posts. Evaluate the blog draft on:\n",
    "            \n",
    "            1. Content depth and accuracy\n",
    "            2. Structure and flow\n",
    "            3. Engagement and reader appeal\n",
    "            4. Technical correctness\n",
    "            5. Language and clarity\n",
    "            6. SEO optimization\n",
    "            7. Use of evidence and examples\n",
    "            \n",
    "            Be specific about what works well and what could be improved. Provide actionable recommendations.\"\"\"),\n",
    "            (\"human\", \"\"\"Review this blog draft on the topic \"{topic}\":\n",
    "            \n",
    "            {draft}\n",
    "            \n",
    "            Provide a comprehensive critique with specific recommendations for improvement.\"\"\"),\n",
    "        ])\n",
    "    \n",
    "    def run(self, state: Dict) -> Dict:\n",
    "        \"\"\"Critique the blog draft and update the state.\"\"\"\n",
    "        print(\"Running Critique Agent\")\n",
    "        try:\n",
    "            critique_chain = self.critique_prompt() | self.llm | StrOutputParser()\n",
    "            critique = critique_chain.invoke({\n",
    "                \"topic\": state.topic,\n",
    "                \"draft\": state.draft\n",
    "            })\n",
    "            \n",
    "            return {**state, \"critique\": critique}\n",
    "        except Exception as e:\n",
    "            return {**state, \"error\": f\"Critique agent error: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevisionAgent:\n",
    "    \"\"\"Agent responsible for revising the blog post based on critique.\"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "    \n",
    "    def revision_prompt(self):\n",
    "        return ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are an expert content reviser. Your task is to improve a blog draft based on editorial critique.\n",
    "            Make substantive improvements to:\n",
    "            \n",
    "            1. Address all critique points thoroughly\n",
    "            2. Enhance the structure and flow\n",
    "            3. Improve language, clarity, and engagement\n",
    "            4. Strengthen evidence and examples\n",
    "            5. Optimize for SEO and readability\n",
    "            \n",
    "            Maintain the markdown formatting and structure of the original while improving the content.\n",
    "            Keep image placeholders with improved descriptions where appropriate.\"\"\"),\n",
    "            (\"human\", \"\"\"Revise this blog draft on \"{topic}\" based on the following critique:\n",
    "            \n",
    "            --- CRITIQUE ---\n",
    "            {critique}\n",
    "            \n",
    "            --- ORIGINAL DRAFT ---\n",
    "            {draft}\n",
    "            \n",
    "            Provide a comprehensive revision that addresses all critique points.\"\"\"),\n",
    "        ])\n",
    "    def run(self, state: Dict) -> Dict:\n",
    "        \"\"\"Revise the blog draft based on critique and update the state.\"\"\"\n",
    "        print(\"Running Revision Agent\")\n",
    "        try:\n",
    "            revision_chain = self.revision_prompt() | self.llm | StrOutputParser()\n",
    "            final_draft = revision_chain.invoke({\n",
    "                \"topic\": state.topic,\n",
    "                \"draft\": state.draft,\n",
    "                \"critique\": state.crtique\n",
    "            })\n",
    "            \n",
    "            return {**state, \"final_draft\": final_draft}\n",
    "        except Exception as e:\n",
    "            return {**state, \"error\": f\"Revision agent error: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationAgent:\n",
    "    \"\"\"Agent responsible for evaluating the final blog post.\"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "    \n",
    "    def evaluation_prompt(self):\n",
    "        return ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are an expert content evaluator. Your task is to provide a comprehensive evaluation of a blog post\n",
    "            based on the following criteria:\n",
    "            \n",
    "            1. Content Quality (1-10): Depth, accuracy, and value to the reader\n",
    "            2. Structure (1-10): Organization, flow, and logical progression\n",
    "            3. Engagement (1-10): Hook, storytelling, and reader interest\n",
    "            4. Technical Accuracy (1-10): Correctness of information and concepts\n",
    "            5. Language & Style (1-10): Clarity, tone, and professionalism\n",
    "            6. SEO Potential (1-10): Keyword usage, meta elements, and searchability\n",
    "            7. Overall Score (1-10): Holistic assessment\n",
    "            \n",
    "            For each criterion, provide a numerical score and brief justification.\n",
    "            Then provide 2-3 strongest aspects and 2-3 areas for improvement.\n",
    "            \n",
    "            Format your response as JSON with the following structure:\n",
    "            {\n",
    "                \"scores\": {\n",
    "                    \"content_quality\": {\"score\": X, \"justification\": \"...\"},\n",
    "                    \"structure\": {\"score\": X, \"justification\": \"...\"},\n",
    "                    \"engagement\": {\"score\": X, \"justification\": \"...\"},\n",
    "                    \"technical_accuracy\": {\"score\": X, \"justification\": \"...\"},\n",
    "                    \"language_style\": {\"score\": X, \"justification\": \"...\"},\n",
    "                    \"seo_potential\": {\"score\": X, \"justification\": \"...\"},\n",
    "                    \"overall\": {\"score\": X, \"justification\": \"...\"}\n",
    "                },\n",
    "                \"strengths\": [\"Strength 1\", \"Strength 2\", \"Strength 3\"],\n",
    "                \"improvements\": [\"Improvement 1\", \"Improvement 2\", \"Improvement 3\"]\n",
    "            }\"\"\"),\n",
    "            (\"human\", \"\"\"Evaluate this final blog post on the topic \"{topic}\":\n",
    "            \n",
    "            {final_draft}\"\"\"),\n",
    "        ])\n",
    "    \n",
    "    def run(self, state: Dict) -> Dict:\n",
    "        \"\"\"Evaluate the final blog post and update the state.\"\"\"\n",
    "        print(\"Running Evaluation Agent\")\n",
    "        try:\n",
    "            evaluation_chain = self.evaluation_prompt() | self.llm | JsonOutputParser()\n",
    "            evaluation = evaluation_chain.invoke({\n",
    "                \"topic\": state.topic,\n",
    "                \"final_draft\": state.final_draft\n",
    "            })\n",
    "            \n",
    "            return {**state, \"evaluation\": evaluation}\n",
    "        except Exception as e:\n",
    "            return {**state, \"error\": f\"Evaluation agent error: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExportAgent:\n",
    "    \"\"\"Agent responsible for exporting the blog post and assets.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.image_downloader = ImageDownloader()\n",
    "    \n",
    "    def create_output_directory(self, topic: str) -> str:\n",
    "        \"\"\"Create an output directory for the blog post and its assets.\"\"\"\n",
    "        # Create a sanitized directory name from the topic\n",
    "        dir_name = re.sub(r'[^\\w\\s-]', '', topic).strip().lower()\n",
    "        dir_name = re.sub(r'[-\\s]+', '-', dir_name)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        output_dir = f\"blog_export_{dir_name}_{timestamp}\"\n",
    "        \n",
    "        # Create directories\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        os.makedirs(os.path.join(output_dir, \"images\"), exist_ok=True)\n",
    "        \n",
    "        return output_dir\n",
    "    \n",
    "    def process_markdown_images(self, markdown_text: str, images: List[Dict], output_dir: str) -> str:\n",
    "        \"\"\"Process image placeholders in markdown and download images.\"\"\"\n",
    "        img_dir = os.path.join(output_dir, \"images\")\n",
    "        \n",
    "        # Find image placeholders in markdown\n",
    "        img_placeholders = re.findall(r'!\\[(.*?)\\]\\((image_placeholder)\\)', markdown_text)\n",
    "        \n",
    "        for i, (alt_text, _) in enumerate(img_placeholders):\n",
    "            if i < len(images):\n",
    "                img = images[i]\n",
    "                img_url = img.get(\"url\")\n",
    "                if img_url:\n",
    "                    # Generate a filename\n",
    "                    img_filename = f\"image_{i+1}.jpg\"\n",
    "                    img_path = os.path.join(img_dir, img_filename)\n",
    "                    \n",
    "                    # Download the image\n",
    "                    result = self.image_downloader.download_image(img_url, img_path)\n",
    "                    \n",
    "                    if result:\n",
    "                        # Replace placeholder with relative path\n",
    "                        markdown_text = markdown_text.replace(\n",
    "                            f\"![{alt_text}](image_placeholder)\",\n",
    "                            f\"![{alt_text}](images/{img_filename})\"\n",
    "                        )\n",
    "        \n",
    "        return markdown_text\n",
    "    \n",
    "    def create_evaluation_report(self, evaluation: Dict, output_dir: str) -> None:\n",
    "        \"\"\"Create an evaluation report markdown file.\"\"\"\n",
    "        if not evaluation:\n",
    "            return\n",
    "        \n",
    "        report_path = os.path.join(output_dir, \"evaluation_report.md\")\n",
    "        \n",
    "        try:\n",
    "            with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(\"# Blog Evaluation Report\\n\\n\")\n",
    "                \n",
    "                # Write scores\n",
    "                f.write(\"## Scores\\n\\n\")\n",
    "                scores = evaluation.get(\"scores\", {})\n",
    "                for criterion, data in scores.items():\n",
    "                    score = data.get(\"score\", \"N/A\")\n",
    "                    justification = data.get(\"justification\", \"No justification provided\")\n",
    "                    f.write(f\"### {criterion.replace('_', ' ').title()}\\n\")\n",
    "                    f.write(f\"**Score:** {score}/10\\n\\n\")\n",
    "                    f.write(f\"**Justification:** {justification}\\n\\n\")\n",
    "                \n",
    "                # Write strengths\n",
    "                f.write(\"## Strengths\\n\\n\")\n",
    "                for strength in evaluation.get(\"strengths\", [\"No strengths identified\"]):\n",
    "                    f.write(f\"- {strength}\\n\")\n",
    "                \n",
    "                # Write improvements\n",
    "                f.write(\"\\n## Areas for Improvement\\n\\n\")\n",
    "                for improvement in evaluation.get(\"improvements\", [\"No improvements identified\"]):\n",
    "                    f.write(f\"- {improvement}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating evaluation report: {str(e)}\")\n",
    "    \n",
    "    def run(self, state: Dict) -> Dict:\n",
    "        \"\"\"Export the blog post and assets to local folder.\"\"\"\n",
    "        print(\"Running Export Agent\")\n",
    "        try:\n",
    "            # Create output directory\n",
    "            output_dir = self.create_output_directory(state[\"topic\"])\n",
    "            \n",
    "            # Process markdown and download images\n",
    "            final_markdown = self.process_markdown_images(\n",
    "                state[\"final_draft\"], \n",
    "                state[\"images\"], \n",
    "                output_dir\n",
    "            )\n",
    "            \n",
    "            # Write the final blog post\n",
    "            blog_path = os.path.join(output_dir, \"blog_post.md\")\n",
    "            with open(blog_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(final_markdown)\n",
    "            \n",
    "            # Create evaluation report\n",
    "            self.create_evaluation_report(state[\"evaluation\"], output_dir)\n",
    "            \n",
    "            # Write metadata\n",
    "            metadata_path = os.path.join(output_dir, \"metadata.json\")\n",
    "            metadata = {\n",
    "                \"topic\": state[\"topic\"],\n",
    "                \"created_at\": datetime.now().isoformat(),\n",
    "                \"title\": state[\"outline\"].get(\"title\", state[\"topic\"]) if isinstance(state[\"outline\"], dict) else state[\"topic\"],\n",
    "                \"evaluation_summary\": {\n",
    "                    \"overall_score\": state[\"evaluation\"].get(\"scores\", {}).get(\"overall\", {}).get(\"score\", \"N/A\") \n",
    "                    if isinstance(state[\"evaluation\"], dict) else \"N/A\"\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            with open(metadata_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(metadata, f, indent=2)\n",
    "            \n",
    "            return {**state, \"output_dir\": output_dir}\n",
    "        except Exception as e:\n",
    "            return {**state, \"error\": f\"Export agent error: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_blog_writing_graph():\n",
    "    \"\"\"Set up the LangGraph for the blog writing process.\"\"\"\n",
    "    # Initialize agents\n",
    "    research_agent = ResearchAgent(llm)\n",
    "    outline_agent = OutlineAgent(llm)\n",
    "    writer_agent = WriterAgent(llm)\n",
    "    critique_agent = CritiqueAgent(llm)\n",
    "    revision_agent = RevisionAgent(llm)\n",
    "    evaluation_agent = EvaluationAgent(llm)\n",
    "    export_agent = ExportAgent()\n",
    "    \n",
    "    # Define the state graph\n",
    "    workflow = StateGraph(BlogWritingState)\n",
    "\n",
    "    # Add nodes with different names than the state keys\n",
    "    workflow.add_node(\"research_node\", lambda state: research_agent.run(state))\n",
    "    workflow.add_node(\"outline_node\", lambda state: outline_agent.run(state))\n",
    "    workflow.add_node(\"draft_node\", lambda state: writer_agent.run(state))\n",
    "    workflow.add_node(\"critique_node\", lambda state: critique_agent.run(state))\n",
    "    workflow.add_node(\"revision_node\", lambda state: revision_agent.run(state))\n",
    "    workflow.add_node(\"evaluation_node\", lambda state: evaluation_agent.run(state))\n",
    "    workflow.add_node(\"export_node\", lambda state: export_agent.run(state))\n",
    "\n",
    "    # Define edges (workflow)\n",
    "    workflow.set_entry_point(\"research_node\")\n",
    "    workflow.add_edge(\"research_node\", \"outline_node\")\n",
    "    workflow.add_edge(\"outline_node\", \"draft_node\")\n",
    "    workflow.add_edge(\"draft_node\", \"critique_node\")\n",
    "    workflow.add_edge(\"critique_node\", \"revision_node\")\n",
    "    workflow.add_edge(\"revision_node\", \"evaluation_node\")\n",
    "    workflow.add_edge(\"evaluation_node\", \"export_node\")\n",
    "    workflow.add_edge(\"export_node\", END)\n",
    "    \n",
    "    # Error handling (optional)\n",
    "    def check_for_errors(state):\n",
    "        if state.error:\n",
    "            return \"error_handler\"\n",
    "        else:\n",
    "            return \"continue_flow\"  # Named return value instead of None\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        \"research_node\",\n",
    "        check_for_errors,\n",
    "        {\n",
    "            \"error_handler\": END,\n",
    "            \"continue_flow\": \"outline_node\"  # Use the named value instead of None\n",
    "        }\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Compile the graph\n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlogWritingApp:\n",
    "    \"\"\"Main application class for the blog writing system.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.graph = setup_blog_writing_graph()\n",
    "        # Set up checkpointing to save the state\n",
    "        self.memory = MemorySaver()\n",
    "    \n",
    "    def write_blog(self, topic: str) -> Dict:\n",
    "        \"\"\"Run the blog writing process for a given topic.\"\"\"\n",
    "        print(f\"Starting blog writing process for topic: {topic}\")\n",
    "        \n",
    "        # Initialize state\n",
    "        initial_state = {\"topic\": topic}\n",
    "        \n",
    "        # Run the graph\n",
    "        try:\n",
    "            # Stream events and handle them appropriately\n",
    "            for output in self.graph.stream(initial_state, {\"configurable\": {\"checkpointer\": self.memory}}):\n",
    "                # Check what type of object output is\n",
    "                if isinstance(output, dict):\n",
    "                    # If it's a dict and contains 'event', handle LangGraph events\n",
    "                    if 'event' in output:\n",
    "                        event_type = output.get('event')\n",
    "                        if event_type == \"on_chain_start\":\n",
    "                            print(f\"Starting: {output.get('name', 'unknown')}\")\n",
    "                        elif event_type == \"on_chain_end\":\n",
    "                            print(f\"Completed: {output.get('name', 'unknown')}\")\n",
    "                        elif event_type == \"on_chain_error\":\n",
    "                            print(f\"Error in {output.get('name', 'unknown')}: {output.get('error', 'unknown error')}\")\n",
    "                    else:\n",
    "                        # If it's a dict without 'event', it might be state data\n",
    "                        print(\"Processing step completed\")\n",
    "                else:\n",
    "                    # Not a dict\n",
    "                    print(f\"Processing: {str(output)[:50]}...\")\n",
    "                    \n",
    "            # Get the final state\n",
    "            final_state = self.memory.get_latest()\n",
    "            \n",
    "            if final_state.error:\n",
    "                print(f\"Process completed with error: {final_state.error}\")\n",
    "            else:\n",
    "                print(f\"Blog writing process completed successfully!\")\n",
    "                print(f\"Output directory: {final_state.output_dir}\")\n",
    "            \n",
    "            # Convert to dict for easier consumption\n",
    "            return dict(final_state)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during blog writing process: {str(e)}\")\n",
    "            return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output guardrails\n",
    "class BlogInputValidator:\n",
    "    \"\"\"Validator for blog writing inputs.\"\"\"\n",
    "    \n",
    "    def validate_topic(self, topic: str) -> Tuple[bool, str]:\n",
    "        \"\"\"Validate the blog topic.\"\"\"\n",
    "        if not topic or len(topic.strip()) < 3:\n",
    "            return False, \"Topic must be at least 3 characters long.\"\n",
    "        \n",
    "        if len(topic) > 200:\n",
    "            return False, \"Topic is too long. Please limit to 200 characters.\"\n",
    "        \n",
    "        return True, \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting blog writing process for topic: Model Context Protocol\n",
      "Running Research Agent\n",
      "Searching for articles on: Model Context Protocol\n",
      "Crawling 5 URLs\n",
      "Crawling URL: https://wandb.ai/onlineinference/mcp/reports/The-Model-Context-Protocol-MCP-by-Anthropic-Origins-functionality-and-impact--VmlldzoxMTY5NDI4MQ\n",
      "Crawling URL: https://www.anthropic.com/news/model-context-protocol\n",
      "Crawling URL: https://medium.com/@subashpalvel/the-hidden-blueprint-of-ai-how-the-model-context-protocol-shapes-our-digital-future-95d4af401dff\n",
      "Crawling URL: https://medium.com/@alekseyrubtsov/the-revolutionary-impact-of-model-context-protocol-mcp-on-working-with-llms-5a85d4330185\n",
      "Crawling URL: https://nshipster.com/model-context-protocol/\n",
      "[INIT].... → Crawl4AI 0.5.0.post4\n",
      "[INIT].... → Crawl4AI 0.5.0.post4\n",
      "[INIT].... → Crawl4AI 0.5.0.post4\n",
      "[INIT].... → Crawl4AI 0.5.0.post4\n",
      "[INIT].... → Crawl4AI 0.5.0.post4\n",
      "[FETCH]... ↓ https://medium.com/@alekseyrubtsov/the-revolutiona... | Status: True | Time: 1.44s\n",
      "[SCRAPE].. ◆ https://medium.com/@alekseyrubtsov/the-revolutiona... | Time: 0.026s\n",
      "[COMPLETE] ● https://medium.com/@alekseyrubtsov/the-revolutiona... | Status: True | Total: 1.48s\n",
      "[FETCH]... ↓ https://nshipster.com/model-context-protocol/... | Status: True | Time: 1.64s\n",
      "[SCRAPE].. ◆ https://nshipster.com/model-context-protocol/... | Time: 0.03s\n",
      "[COMPLETE] ● https://nshipster.com/model-context-protocol/... | Status: True | Total: 1.69s\n",
      "[FETCH]... ↓ https://www.anthropic.com/news/model-context-proto... | Status: True | Time: 1.80s\n",
      "[SCRAPE].. ◆ https://www.anthropic.com/news/model-context-proto... | Time: 0.015s\n",
      "[COMPLETE] ● https://www.anthropic.com/news/model-context-proto... | Status: True | Total: 1.84s\n",
      "[FETCH]... ↓ https://wandb.ai/onlineinference/mcp/reports/The-M... | Status: True | Time: 2.03s\n",
      "[SCRAPE].. ◆ https://wandb.ai/onlineinference/mcp/reports/The-M... | Time: 0.001s\n",
      "[COMPLETE] ● https://wandb.ai/onlineinference/mcp/reports/The-M... | Status: True | Total: 2.05s\n",
      "[FETCH]... ↓ https://medium.com/@subashpalvel/the-hidden-bluepr... | Status: True | Time: 2.88s\n",
      "[SCRAPE].. ◆ https://medium.com/@subashpalvel/the-hidden-bluepr... | Time: 0.017s\n",
      "[COMPLETE] ● https://medium.com/@subashpalvel/the-hidden-bluepr... | Status: True | Total: 2.92s\n",
      "Processing step completed\n",
      "Running Outline Agent\n",
      "Error during blog writing process: 'BlogWritingState' object is not a mapping\n",
      "\n",
      "Process completed!\n",
      "No output directory was created. Check for errors in the process.\n",
      "Error: 'BlogWritingState' object is not a mapping\n"
     ]
    }
   ],
   "source": [
    "# Demo usage\n",
    "def run_demo():\n",
    "    \"\"\"Run a demonstration of the blog writing system.\"\"\"\n",
    "    # Set up the application\n",
    "    app = BlogWritingApp()\n",
    "    validator = BlogInputValidator()\n",
    "    \n",
    "    # Get user input\n",
    "    topic = input(\"Enter blog topic: \")\n",
    "    \n",
    "    # Validate input\n",
    "    is_valid, error_message = validator.validate_topic(topic)\n",
    "    if not is_valid:\n",
    "        print(f\"Invalid input: {error_message}\")\n",
    "        return\n",
    "    \n",
    "    # Run the blog writing process\n",
    "    result = app.write_blog(topic)\n",
    "    \n",
    "    print(\"\\nProcess completed!\")\n",
    "    \n",
    "    # Print summary - safer access with defaults\n",
    "    if isinstance(result, dict):\n",
    "        # Check if output directory was created\n",
    "        output_dir = result.get(\"output_dir\")\n",
    "        if output_dir:\n",
    "            print(f\"Blog post saved to: {output_dir}/blog_post.md\")\n",
    "            print(f\"Evaluation report: {output_dir}/evaluation_report.md\")\n",
    "            \n",
    "            # Show evaluation summary if available\n",
    "            evaluation = result.get(\"evaluation\", {})\n",
    "            if isinstance(evaluation, dict) and \"scores\" in evaluation:\n",
    "                scores = evaluation.get(\"scores\", {})\n",
    "                if \"overall\" in scores:\n",
    "                    print(f\"\\nOverall score: {scores['overall'].get('score', 'N/A')}/10\")\n",
    "                \n",
    "                strengths = evaluation.get(\"strengths\", [])\n",
    "                if strengths:\n",
    "                    print(\"\\nStrengths:\")\n",
    "                    for strength in strengths[:3]:\n",
    "                        print(f\"- {strength}\")\n",
    "        else:\n",
    "            print(\"No output directory was created. Check for errors in the process.\")\n",
    "            error = result.get(\"error\", \"Unknown error\")\n",
    "            if error:\n",
    "                print(f\"Error: {error}\")\n",
    "    else:\n",
    "        print(\"Unexpected result format. Process may not have completed successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
